{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Omics-analysis Seeding comprehensive analysis in their named directories (e.g., BMI ), the repository links to technical issues documented in physalia , Mixed-Models , software-notes and other sister repositories: SUMSTATS , FM-pipeline , PW-pipeline , hess-pipeline , TWAS-pipeline , EWAS-fusion . for fine-mapping, pathway analysis, TWAS, Mendelian randomisation, predictive analytics and other topics as highlighted in the wiki page . Earlier or broader aspects have been reflected in the following repositories: Haplotype-Analysis , misc , R . The figure below was generated with eQTL.R .","title":""},{"location":"#omics-analysis","text":"Seeding comprehensive analysis in their named directories (e.g., BMI ), the repository links to technical issues documented in physalia , Mixed-Models , software-notes and other sister repositories: SUMSTATS , FM-pipeline , PW-pipeline , hess-pipeline , TWAS-pipeline , EWAS-fusion . for fine-mapping, pathway analysis, TWAS, Mendelian randomisation, predictive analytics and other topics as highlighted in the wiki page . Earlier or broader aspects have been reflected in the following repositories: Haplotype-Analysis , misc , R . The figure below was generated with eQTL.R .","title":"Omics-analysis"},{"location":"genomics/","text":"Genomics bigOmics, https://bigomics.ch/ Bioconductor support, https://support.bioconductor.org/ Bailey lab, https://github.com/bailey-lab CellProfiler, https://cellprofiler.org/ cerno Biosciencec, https://cernobioscience.com/ Course on GWAS by Matti Pirinen, https://www.mv.helsinki.fi/home/mjxpirin/GWAS_course/ d3blocks, https://github.com/d3blocks/d3blocks ( documentation ) FUMA GWAS, https://fuma.ctglab.nl/ ( https://github.com/Kyoko-wtnb/FUMA-webapp/ ) GA4GH, https://www.ga4gh.org/ GATK, https://gatk.broadinstitute.org/hc/en-us GBMI, https://www.globalbiobankmeta.org/resources Glossary of Genetics, https://www.genome.gov/genetics-glossary G*Power, https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower , https://stats.oarc.ucla.edu/other/gpower/ GRCh38 reference genome, https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/ GTEx, https://www.gtexportal.org/home/ ( datasets ) GWAS atlas, https://atlas.ctglab.nl/traitDB GWAS Catalog, https://www.ebi.ac.uk/gwas/ GWAS Central, https://www.gwascentral.org/ hail, https://hail.is/index.html LDlink, https://ldlink.nci.nih.gov/?tab=home. LocusTrack, https://gump.qimr.edu.au/general/gabrieC/LocusTrack/index.html JASPAR, https://jaspar.genereg.net/ NCBI, https://www.ncbi.nlm.nih.gov/ NyuWa Chinese Population Variant Database (NCVD): http://bigdata.ibp.ac.cn/NyuWa_variants/ OpenTargets, https://genetics.opentargets.org/ Our Future Health, https://ourfuturehealth.org.uk/ PGSCatalog, http://www.pgscatalog.org/ ( Calculator , Nat Genet & Cell Genomics papers) Pheno.AI, https://knowledgebase.pheno.ai/ PerkinElmer, https://www.perkinelmer.com/ PLINK2 mailing list, https://groups.google.com/g/plink2-users RegulomeDB, https://regulomedb.org/regulome-search/ Sequence Ontology, http://www.sequenceontology.org/ SNiPA, https://snipa.helmholtz-muenchen.de/snipa3/ SNP2TFBS, https://ccg.epfl.ch/snp2tfbs/ Systems-Genomics, https://systems-genomics.slack.com/","title":"Genomics"},{"location":"genomics/#genomics","text":"bigOmics, https://bigomics.ch/ Bioconductor support, https://support.bioconductor.org/ Bailey lab, https://github.com/bailey-lab CellProfiler, https://cellprofiler.org/ cerno Biosciencec, https://cernobioscience.com/ Course on GWAS by Matti Pirinen, https://www.mv.helsinki.fi/home/mjxpirin/GWAS_course/ d3blocks, https://github.com/d3blocks/d3blocks ( documentation ) FUMA GWAS, https://fuma.ctglab.nl/ ( https://github.com/Kyoko-wtnb/FUMA-webapp/ ) GA4GH, https://www.ga4gh.org/ GATK, https://gatk.broadinstitute.org/hc/en-us GBMI, https://www.globalbiobankmeta.org/resources Glossary of Genetics, https://www.genome.gov/genetics-glossary G*Power, https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower , https://stats.oarc.ucla.edu/other/gpower/ GRCh38 reference genome, https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/ GTEx, https://www.gtexportal.org/home/ ( datasets ) GWAS atlas, https://atlas.ctglab.nl/traitDB GWAS Catalog, https://www.ebi.ac.uk/gwas/ GWAS Central, https://www.gwascentral.org/ hail, https://hail.is/index.html LDlink, https://ldlink.nci.nih.gov/?tab=home. LocusTrack, https://gump.qimr.edu.au/general/gabrieC/LocusTrack/index.html JASPAR, https://jaspar.genereg.net/ NCBI, https://www.ncbi.nlm.nih.gov/ NyuWa Chinese Population Variant Database (NCVD): http://bigdata.ibp.ac.cn/NyuWa_variants/ OpenTargets, https://genetics.opentargets.org/ Our Future Health, https://ourfuturehealth.org.uk/ PGSCatalog, http://www.pgscatalog.org/ ( Calculator , Nat Genet & Cell Genomics papers) Pheno.AI, https://knowledgebase.pheno.ai/ PerkinElmer, https://www.perkinelmer.com/ PLINK2 mailing list, https://groups.google.com/g/plink2-users RegulomeDB, https://regulomedb.org/regulome-search/ Sequence Ontology, http://www.sequenceontology.org/ SNiPA, https://snipa.helmholtz-muenchen.de/snipa3/ SNP2TFBS, https://ccg.epfl.ch/snp2tfbs/ Systems-Genomics, https://systems-genomics.slack.com/","title":"Genomics"},{"location":"proteomics/","text":"Proteomics AlphaFold3, https://github.com/google-deepmind/alphafold3 casanovo, https://github.com/Noble-Lab/casanovo CoffeeProt, https://coffeeprot.com/ Consortium for Top-Down proteomics, https://www.topdownproteomics.org/ DiaNN, https://github.com/vdemichev/DiaNN FreqPipe, https://fragpipe.nesvilab.org/ Human Proteome Project (HPP), https://hupo.org/human-proteome-project (Resources, https://hupo.org/HPP-Resources ) InstaNovo GitHub, https://github.com/instadeepai/InstaNovo HuggingFace, https://huggingface.co/spaces/InstaDeepAI/InstaNovo High-confidence ProteomeTools dataset https://doi.org/10.57967/hf/3822 Nine species Benchmark, https://doi.org/10.57967/hf/3821 MassiveFold, https://github.com/GBLille/MassiveFold MaxQuant, https://maxquant.org/ ( Mailing list ) Mass++, https://mspp.ninja/download/ MS-GF+, https://msgfplus.github.io/ OpenFold, https://openfold.io/ Perseus, https://maxquant.net/perseus/ Peptigram, http://bioware.ucd.ie/peptigram/ Protein Structure Prediction Center, https://predictioncenter.org/ ProteomeXchange, https://www.proteomexchange.org/ ProteoMapper Online, https://peptideatlas.org/map/ RFdiffusion, https://github.com/RosettaCommons/RFdiffusion Sage, https://sage-docs.vercel.app/ Sashimi, https://sourceforge.net/projects/sashimi Skyline, https://skyline.ms/project/home/begin.view Spectranaut, https://biognosys.com/software/spectronaut/","title":"Proteomics"},{"location":"proteomics/#proteomics","text":"AlphaFold3, https://github.com/google-deepmind/alphafold3 casanovo, https://github.com/Noble-Lab/casanovo CoffeeProt, https://coffeeprot.com/ Consortium for Top-Down proteomics, https://www.topdownproteomics.org/ DiaNN, https://github.com/vdemichev/DiaNN FreqPipe, https://fragpipe.nesvilab.org/ Human Proteome Project (HPP), https://hupo.org/human-proteome-project (Resources, https://hupo.org/HPP-Resources ) InstaNovo GitHub, https://github.com/instadeepai/InstaNovo HuggingFace, https://huggingface.co/spaces/InstaDeepAI/InstaNovo High-confidence ProteomeTools dataset https://doi.org/10.57967/hf/3822 Nine species Benchmark, https://doi.org/10.57967/hf/3821 MassiveFold, https://github.com/GBLille/MassiveFold MaxQuant, https://maxquant.org/ ( Mailing list ) Mass++, https://mspp.ninja/download/ MS-GF+, https://msgfplus.github.io/ OpenFold, https://openfold.io/ Perseus, https://maxquant.net/perseus/ Peptigram, http://bioware.ucd.ie/peptigram/ Protein Structure Prediction Center, https://predictioncenter.org/ ProteomeXchange, https://www.proteomexchange.org/ ProteoMapper Online, https://peptideatlas.org/map/ RFdiffusion, https://github.com/RosettaCommons/RFdiffusion Sage, https://sage-docs.vercel.app/ Sashimi, https://sourceforge.net/projects/sashimi Skyline, https://skyline.ms/project/home/begin.view Spectranaut, https://biognosys.com/software/spectronaut/","title":"Proteomics"},{"location":"resources/","text":"Resources Annotation The Ensembl public MySQL Servers The following script gives information on genes from ENSEMBL as well as attributes (columns) that contains gene . library(biomaRt) listMarts() mart <- useMart(\"ENSEMBL_MART_FUNCGEN\") listDatasets(mart) mart <- useMart(\"ensembl\") listDatasets(mart) ensembl <- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\", host=\"grch37.ensembl.org\", path=\"/biomart/martservice\") attr <- listAttributes(ensembl) attr_select <- c('ensembl_gene_id', 'chromosome_name', 'start_position', 'end_position', 'description', 'hgnc_symbol', 'transcription_start_site') gene <- getBM(attributes = attr_select, mart = ensembl) filter <- listFilters(ensembl) searchFilters(mart = ensembl, pattern = \"gene\") See also https://sites.google.com/site/jpopgen/wgsa for precompiled annotation. Alternatively, # GENCODE v19 url <- \"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_19/gencode.v19.chr_patch_hapl_scaff.annotation.gtf.gz\" gtf <- rtracklayer::import(url) gencode <- as.data.frame(gtf) Biobanks China Kadoorie Biobank https://www.ckbiobank.org/ https://pheweb.ckbiobank.org/ Estonian Biobank https://genomics.ut.ee/en/ FinGenn https://www.finngen.fi/en Japan Biobank https://biobankjp.org/ https://humandbs.biosciencedbc.jp/en/hum0014-v21 Our Future Health, https://research.ourfuturehealth.org.uk/ UK Biobank AMS ( access@ukbiobank.ac.uk ), Access_019-Access-Management-System-User-Guide-V4.0.pdf , messages . Accessing data guide, http://biobank.ctsu.ox.ac.uk/crystal/exinfo.cgi?src=AccessingData . Allele frequency browser, https://afb.ukbiobank.ac.uk/ . AstraZeneca PheWAS Portal, https://azphewas.com/ ( CGR Proteogenomics Portal ). Data access guide 3.2, https://biobank.ndph.ox.ac.uk/~bbdatan/Data_Access_Guide_v3.2.pdf . DNAnexus, GitHub , landing , partnerships Evoker, https://www.sanger.ac.uk/tool/evoker/ . Genetic correlation between traits and disorders, https://ukbb-rg.hail.is/ . Imputation, http://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/impute_ukb_v1.pdf . Gene ATLAS, http://geneatlas.roslin.ed.ac.uk/ . genebass . UKB-Biobank, https://github.com/UK-Biobank ( ukbrapR , ukbnmr ) PHESANT . Online showcase, https://biobank.ndph.ox.ac.uk/ukb/ ( Showcase User Guide ). Pan-UK Biobank , GWAS sumstats and GitHub . COVID-19 data , format and field . Catalog eQTL Catalog, https://www.ebi.ac.uk/eqtl/ GWAS Catalog, https://www.ebi.ac.uk/gwas/ PheWAS Catalog, https://phewascatalog.org/ EFO https://www.ebi.ac.uk/efo/ Example code, library(ontologyIndex) id <- function(ontology) { inflammatory <- grep(ontology$name,pattern=\"inflammatory\") immune <- grep(ontology$name,pattern=\"immune\") inf <- union(inflammatory,immune) list(id=ontology$id[inf],name=ontology$name[inf]) } # GO data(go) goidname <- id(go) # EFO file <- \"efo.obo\" get_relation_names(file) efo <- get_ontology(file, extract_tags=\"everything\") length(efo) # 89 length(efo$id) # 27962 efoidname <- id(efo) diseases <- get_descendants(efo,\"EFO:0000408\") efo_0000540 <- get_descendants(efo,\"EFO:0000540\") efo_0000540name <- efo$name[efo_0000540] isd <- data.frame(efo_0000540,efo_0000540name) save(efo,diseases,isd,efoidname,goidname, file=\"work/efo.rda\") write.table(isd,file=\"efo_0000540.csv\",col.names=FALSE,row.names=FALSE,sep=\",\") pdf(\"efo_0000540.pdf\",height=15,width=15) library(ontologyPlot) onto_plot(efo,efo_0000540) dev.off() eQTLGen http://www.eqtlgen.org/ MetaMapLite https://metamap.nlm.nih.gov/MetaMapLite.shtml MR-Base/OpenGWAS http://www.mrbase.org ( MRCIEU demo ) https://gwas.mrcieu.ac.uk OpenTargets These reflects v4 using GraphQL, https://platform-docs.opentargets.org/data-access/graphql-api . Our first example is from the document (except ENSG00000164308) whose output is as ERAP2.json . #!/usr/bin/bash # https://platform.opentargets.org/api module load ceuadmin/R Rscript -e ' ERAP2 <- subset(pQTLdata::caprion,Gene==\"ERAP2\") ERAP2$ensGenes data <- jsonlite::fromJSON(\"ERAP2.json\") diseases_data <- data$data$target$associatedDiseases$rows diseases_data <- tidyr::unnest(diseases_data, cols = everything(), names_sep = \"_\") write.table(diseases_data, file = \"ERAP2.tsv\", sep = \"\\t\", row.names = FALSE, quote = FALSE) ' In fact it is effectively done as follows, library(httr) library(jsonlite) gene_id <- \"ENSG00000164308\" query_string <- \" query target($ensemblId: String!){ target(ensemblId: $ensemblId){ id approvedSymbol associatedDiseases { count rows { disease { id name } datasourceScores { id score } } } } } \" base_url <- \"https://api.platform.opentargets.org/api/v4/graphql\" variables <- list(\"ensemblId\" = gene_id) post_body <- list(query = query_string, variables = variables) r <- httr::POST(url = base_url, body = post_body, encode = 'json') if (status_code(r) == 200) { data <- iconv(r, \"\", \"ASCII\") content <- jsonlite::fromJSON(data) } else { print(paste(\"Request failed with status code\", status_code(r))) } # Step 1: Access the nested data target <- content$data$target # Step 2: Extract scalar fields scalar_fields <- data.frame( Field = c(\"ID\", \"Approved Symbol\", \"Biotype\"), Value = c(target$id, target$approvedSymbol, target$biotype) ) # Step 3: Generate a table for scalar fields cat(\"### Scalar Fields\\n\") knitr::kable(scalar_fields, caption = \"Basic Information\") # Step 4: Generate a table for geneticConstraint cat(\"\\n### Genetic Constraint\\n\") knitr::kable(target$geneticConstraint, caption = \"Genetic Constraint Metrics\") # Step 5: Generate a table for tractability cat(\"\\n### Tractability\\n\") knitr::kable(target$tractability, caption = \"Tractability Information\") where jsonlite::fromJSON(content(r,\"text\")) is also possible when R is nicely compiled with libiconv. A Bash implementation is copied here curl 'https://api.platform.opentargets.org/api/v4/graphql' \\ -H 'Accept-Encoding: gzip, deflate, br' \\ -H 'Content-Type: application/json' \\ -H 'Accept: application/json' \\ -H 'Connection: keep-alive' \\ -H 'DNT: 1' \\ -H 'Origin: https://api.platform.opentargets.org' \\ --data-binary '{\"query\":\"query targetInfo {\\n target(ensemblId: \\\"ENSG00000164308\\\") {\\n id\\n approvedSymbol\\n biotype\\n geneticConstraint {\\n constraintType\\n exp\\n obs\\n score\\n oe\\n oeLower\\n oeUpper\\n }\\n tractability {\\n label\\n modality\\n value\\n }\\n }\\n}\\n\"}' \\ --compressed The Python script can be used directly without change import requests import json gene_id = \"ENSG00000164308\" query_string = \"\"\" query target($ensemblId: String!){ target(ensemblId: $ensemblId){ id approvedSymbol biotype geneticConstraint { constraintType exp obs score oe oeLower oeUpper } tractability { label modality value } } } \"\"\" variables = {\"ensemblId\": gene_id} base_url = \"https://api.platform.opentargets.org/api/v4/graphql\" r = requests.post(base_url, json={\"query\": query_string, \"variables\": variables}) print(r.status_code) api_response = json.loads(r.text) print(api_response) Lastly we turn to R, which again gets around httr::content(r) for iconvlist() with iconv() . library(httr) library(jsonlite) gene_id <- \"ENSG00000164308\" query_string = \" query target($ensemblId: String!){ target(ensemblId: $ensemblId){ id approvedSymbol biotype geneticConstraint { constraintType exp obs score oe oeLower oeUpper } tractability { label modality value } } } \" base_url <- \"https://api.platform.opentargets.org/api/v4/graphql\" variables <- list(\"ensemblId\" = gene_id) post_body <- list(query = query_string, variables = variables) r <- httr::POST(url=base_url, body=post_body, encode='json') data <- iconv(r, \"\", \"ASCII\") content <- jsonlite::fromJSON(data) rentrez The relevant URLs are as follows, https://cran.r-project.org/web/packages/rentrez/vignettes/rentrez_tutorial.html https://pubmed.ncbi.nlm.nih.gov/ https://www.ncbi.nlm.nih.gov/pmc/pmctopmid/ with example code, library(rentrez) entrez_dbs() entrez_db_links(\"pubmed\") pubmed_fields <- entrez_db_searchable(\"pubmed\") # set_entrez_key(\"\") Sys.getenv(\"ENTREZ_KEY\") term <- \"pQTLs OR (protein AND quantitative AND trait AND loci) AND human [MH] AND (plasma OR Serum)\" r <- entrez_search(db=\"pubmed\",term=term,use_history=TRUE) class(r) names(r) with(r,web_history) unlink(paste(\"pubmed\",c(\"fetch\",\"summary\"),sep=\".\")) fields <- c(\"uid\", \"pubdate\", \"sortfirstauthor\", \"title\", \"source\", \"volume\", \"pages\") for(i in seq(1,with(r,count),50)) { cat(i+49, \"records downloaded\\r\") f <- entrez_fetch(db=\"pubmed\", web_history=with(r,web_history), rettype=\"text\", retmax=50, retstart=i) write.table(f, col.names=FALSE, row.names=FALSE, file=\"pubmed.fetch\", append=TRUE) s <- entrez_summary(db=\"pubmed\", web_history=with(r,web_history), rettype=\"text\", retmax=50, retstart=i) e <- extract_from_esummary(s, fields) write.table(t(e), col.names=FALSE, row.names=FALSE, file=\"pubmed.summary\", append=TRUE, sep=\"\\t\") } id <- 600807 upload <- entrez_post(db=\"omim\", id=id) asthma_variants <- entrez_link(dbfrom=\"omim\", db=\"clinvar\", cmd=\"neighbor_history\", web_history=upload) asthma_variants snp_links <- entrez_link(dbfrom=\"clinvar\", db=\"snp\", web_history=asthma_variants$web_histories$omim_clinvar, cmd=\"neighbor_history\") all_links <- entrez_link(dbfrom='pubmed', id=id, db='all') Roadmap http://www.roadmapepigenomics.org/ snakemake workflow catalogue https://snakemake.github.io/snakemake-workflow-catalog/ TWAS MetaXcan, https://github.com/hakyimlab/MetaXcan FUSION, http://gusevlab.org/projects/fusion/ OmicsPred, https://www.omicspred.org/ PredictDB data repository, http://predictdb.org/ TWAS-hub, http://twas-hub.org/ Other links CALIBER . deCode summary statistics Galaxy Europe Genome in a Bottle WGS samples genego . MVP GWAS summary statistics, https://ftp.ncbi.nlm.nih.gov/dbgap/studies/phs002453/analyses/ . The Australian e-Health Research Centre . Institute of Translational Genomics and omicscience . idep NCBI account ( settings ).","title":"Resources"},{"location":"resources/#resources","text":"","title":"Resources"},{"location":"resources/#annotation","text":"The Ensembl public MySQL Servers The following script gives information on genes from ENSEMBL as well as attributes (columns) that contains gene . library(biomaRt) listMarts() mart <- useMart(\"ENSEMBL_MART_FUNCGEN\") listDatasets(mart) mart <- useMart(\"ensembl\") listDatasets(mart) ensembl <- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\", host=\"grch37.ensembl.org\", path=\"/biomart/martservice\") attr <- listAttributes(ensembl) attr_select <- c('ensembl_gene_id', 'chromosome_name', 'start_position', 'end_position', 'description', 'hgnc_symbol', 'transcription_start_site') gene <- getBM(attributes = attr_select, mart = ensembl) filter <- listFilters(ensembl) searchFilters(mart = ensembl, pattern = \"gene\") See also https://sites.google.com/site/jpopgen/wgsa for precompiled annotation. Alternatively, # GENCODE v19 url <- \"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_19/gencode.v19.chr_patch_hapl_scaff.annotation.gtf.gz\" gtf <- rtracklayer::import(url) gencode <- as.data.frame(gtf)","title":"Annotation"},{"location":"resources/#biobanks","text":"China Kadoorie Biobank https://www.ckbiobank.org/ https://pheweb.ckbiobank.org/ Estonian Biobank https://genomics.ut.ee/en/ FinGenn https://www.finngen.fi/en Japan Biobank https://biobankjp.org/ https://humandbs.biosciencedbc.jp/en/hum0014-v21 Our Future Health, https://research.ourfuturehealth.org.uk/ UK Biobank AMS ( access@ukbiobank.ac.uk ), Access_019-Access-Management-System-User-Guide-V4.0.pdf , messages . Accessing data guide, http://biobank.ctsu.ox.ac.uk/crystal/exinfo.cgi?src=AccessingData . Allele frequency browser, https://afb.ukbiobank.ac.uk/ . AstraZeneca PheWAS Portal, https://azphewas.com/ ( CGR Proteogenomics Portal ). Data access guide 3.2, https://biobank.ndph.ox.ac.uk/~bbdatan/Data_Access_Guide_v3.2.pdf . DNAnexus, GitHub , landing , partnerships Evoker, https://www.sanger.ac.uk/tool/evoker/ . Genetic correlation between traits and disorders, https://ukbb-rg.hail.is/ . Imputation, http://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/impute_ukb_v1.pdf . Gene ATLAS, http://geneatlas.roslin.ed.ac.uk/ . genebass . UKB-Biobank, https://github.com/UK-Biobank ( ukbrapR , ukbnmr ) PHESANT . Online showcase, https://biobank.ndph.ox.ac.uk/ukb/ ( Showcase User Guide ). Pan-UK Biobank , GWAS sumstats and GitHub . COVID-19 data , format and field .","title":"Biobanks"},{"location":"resources/#catalog","text":"eQTL Catalog, https://www.ebi.ac.uk/eqtl/ GWAS Catalog, https://www.ebi.ac.uk/gwas/ PheWAS Catalog, https://phewascatalog.org/","title":"Catalog"},{"location":"resources/#efo","text":"https://www.ebi.ac.uk/efo/ Example code, library(ontologyIndex) id <- function(ontology) { inflammatory <- grep(ontology$name,pattern=\"inflammatory\") immune <- grep(ontology$name,pattern=\"immune\") inf <- union(inflammatory,immune) list(id=ontology$id[inf],name=ontology$name[inf]) } # GO data(go) goidname <- id(go) # EFO file <- \"efo.obo\" get_relation_names(file) efo <- get_ontology(file, extract_tags=\"everything\") length(efo) # 89 length(efo$id) # 27962 efoidname <- id(efo) diseases <- get_descendants(efo,\"EFO:0000408\") efo_0000540 <- get_descendants(efo,\"EFO:0000540\") efo_0000540name <- efo$name[efo_0000540] isd <- data.frame(efo_0000540,efo_0000540name) save(efo,diseases,isd,efoidname,goidname, file=\"work/efo.rda\") write.table(isd,file=\"efo_0000540.csv\",col.names=FALSE,row.names=FALSE,sep=\",\") pdf(\"efo_0000540.pdf\",height=15,width=15) library(ontologyPlot) onto_plot(efo,efo_0000540) dev.off()","title":"EFO"},{"location":"resources/#eqtlgen","text":"http://www.eqtlgen.org/","title":"eQTLGen"},{"location":"resources/#metamaplite","text":"https://metamap.nlm.nih.gov/MetaMapLite.shtml","title":"MetaMapLite"},{"location":"resources/#mr-baseopengwas","text":"http://www.mrbase.org ( MRCIEU demo ) https://gwas.mrcieu.ac.uk","title":"MR-Base/OpenGWAS"},{"location":"resources/#opentargets","text":"These reflects v4 using GraphQL, https://platform-docs.opentargets.org/data-access/graphql-api . Our first example is from the document (except ENSG00000164308) whose output is as ERAP2.json . #!/usr/bin/bash # https://platform.opentargets.org/api module load ceuadmin/R Rscript -e ' ERAP2 <- subset(pQTLdata::caprion,Gene==\"ERAP2\") ERAP2$ensGenes data <- jsonlite::fromJSON(\"ERAP2.json\") diseases_data <- data$data$target$associatedDiseases$rows diseases_data <- tidyr::unnest(diseases_data, cols = everything(), names_sep = \"_\") write.table(diseases_data, file = \"ERAP2.tsv\", sep = \"\\t\", row.names = FALSE, quote = FALSE) ' In fact it is effectively done as follows, library(httr) library(jsonlite) gene_id <- \"ENSG00000164308\" query_string <- \" query target($ensemblId: String!){ target(ensemblId: $ensemblId){ id approvedSymbol associatedDiseases { count rows { disease { id name } datasourceScores { id score } } } } } \" base_url <- \"https://api.platform.opentargets.org/api/v4/graphql\" variables <- list(\"ensemblId\" = gene_id) post_body <- list(query = query_string, variables = variables) r <- httr::POST(url = base_url, body = post_body, encode = 'json') if (status_code(r) == 200) { data <- iconv(r, \"\", \"ASCII\") content <- jsonlite::fromJSON(data) } else { print(paste(\"Request failed with status code\", status_code(r))) } # Step 1: Access the nested data target <- content$data$target # Step 2: Extract scalar fields scalar_fields <- data.frame( Field = c(\"ID\", \"Approved Symbol\", \"Biotype\"), Value = c(target$id, target$approvedSymbol, target$biotype) ) # Step 3: Generate a table for scalar fields cat(\"### Scalar Fields\\n\") knitr::kable(scalar_fields, caption = \"Basic Information\") # Step 4: Generate a table for geneticConstraint cat(\"\\n### Genetic Constraint\\n\") knitr::kable(target$geneticConstraint, caption = \"Genetic Constraint Metrics\") # Step 5: Generate a table for tractability cat(\"\\n### Tractability\\n\") knitr::kable(target$tractability, caption = \"Tractability Information\") where jsonlite::fromJSON(content(r,\"text\")) is also possible when R is nicely compiled with libiconv. A Bash implementation is copied here curl 'https://api.platform.opentargets.org/api/v4/graphql' \\ -H 'Accept-Encoding: gzip, deflate, br' \\ -H 'Content-Type: application/json' \\ -H 'Accept: application/json' \\ -H 'Connection: keep-alive' \\ -H 'DNT: 1' \\ -H 'Origin: https://api.platform.opentargets.org' \\ --data-binary '{\"query\":\"query targetInfo {\\n target(ensemblId: \\\"ENSG00000164308\\\") {\\n id\\n approvedSymbol\\n biotype\\n geneticConstraint {\\n constraintType\\n exp\\n obs\\n score\\n oe\\n oeLower\\n oeUpper\\n }\\n tractability {\\n label\\n modality\\n value\\n }\\n }\\n}\\n\"}' \\ --compressed The Python script can be used directly without change import requests import json gene_id = \"ENSG00000164308\" query_string = \"\"\" query target($ensemblId: String!){ target(ensemblId: $ensemblId){ id approvedSymbol biotype geneticConstraint { constraintType exp obs score oe oeLower oeUpper } tractability { label modality value } } } \"\"\" variables = {\"ensemblId\": gene_id} base_url = \"https://api.platform.opentargets.org/api/v4/graphql\" r = requests.post(base_url, json={\"query\": query_string, \"variables\": variables}) print(r.status_code) api_response = json.loads(r.text) print(api_response) Lastly we turn to R, which again gets around httr::content(r) for iconvlist() with iconv() . library(httr) library(jsonlite) gene_id <- \"ENSG00000164308\" query_string = \" query target($ensemblId: String!){ target(ensemblId: $ensemblId){ id approvedSymbol biotype geneticConstraint { constraintType exp obs score oe oeLower oeUpper } tractability { label modality value } } } \" base_url <- \"https://api.platform.opentargets.org/api/v4/graphql\" variables <- list(\"ensemblId\" = gene_id) post_body <- list(query = query_string, variables = variables) r <- httr::POST(url=base_url, body=post_body, encode='json') data <- iconv(r, \"\", \"ASCII\") content <- jsonlite::fromJSON(data)","title":"OpenTargets"},{"location":"resources/#rentrez","text":"The relevant URLs are as follows, https://cran.r-project.org/web/packages/rentrez/vignettes/rentrez_tutorial.html https://pubmed.ncbi.nlm.nih.gov/ https://www.ncbi.nlm.nih.gov/pmc/pmctopmid/ with example code, library(rentrez) entrez_dbs() entrez_db_links(\"pubmed\") pubmed_fields <- entrez_db_searchable(\"pubmed\") # set_entrez_key(\"\") Sys.getenv(\"ENTREZ_KEY\") term <- \"pQTLs OR (protein AND quantitative AND trait AND loci) AND human [MH] AND (plasma OR Serum)\" r <- entrez_search(db=\"pubmed\",term=term,use_history=TRUE) class(r) names(r) with(r,web_history) unlink(paste(\"pubmed\",c(\"fetch\",\"summary\"),sep=\".\")) fields <- c(\"uid\", \"pubdate\", \"sortfirstauthor\", \"title\", \"source\", \"volume\", \"pages\") for(i in seq(1,with(r,count),50)) { cat(i+49, \"records downloaded\\r\") f <- entrez_fetch(db=\"pubmed\", web_history=with(r,web_history), rettype=\"text\", retmax=50, retstart=i) write.table(f, col.names=FALSE, row.names=FALSE, file=\"pubmed.fetch\", append=TRUE) s <- entrez_summary(db=\"pubmed\", web_history=with(r,web_history), rettype=\"text\", retmax=50, retstart=i) e <- extract_from_esummary(s, fields) write.table(t(e), col.names=FALSE, row.names=FALSE, file=\"pubmed.summary\", append=TRUE, sep=\"\\t\") } id <- 600807 upload <- entrez_post(db=\"omim\", id=id) asthma_variants <- entrez_link(dbfrom=\"omim\", db=\"clinvar\", cmd=\"neighbor_history\", web_history=upload) asthma_variants snp_links <- entrez_link(dbfrom=\"clinvar\", db=\"snp\", web_history=asthma_variants$web_histories$omim_clinvar, cmd=\"neighbor_history\") all_links <- entrez_link(dbfrom='pubmed', id=id, db='all')","title":"rentrez"},{"location":"resources/#roadmap","text":"http://www.roadmapepigenomics.org/","title":"Roadmap"},{"location":"resources/#snakemake-workflow-catalogue","text":"https://snakemake.github.io/snakemake-workflow-catalog/","title":"snakemake workflow catalogue"},{"location":"resources/#twas","text":"MetaXcan, https://github.com/hakyimlab/MetaXcan FUSION, http://gusevlab.org/projects/fusion/ OmicsPred, https://www.omicspred.org/ PredictDB data repository, http://predictdb.org/ TWAS-hub, http://twas-hub.org/","title":"TWAS"},{"location":"resources/#other-links","text":"CALIBER . deCode summary statistics Galaxy Europe Genome in a Bottle WGS samples genego . MVP GWAS summary statistics, https://ftp.ncbi.nlm.nih.gov/dbgap/studies/phs002453/analyses/ . The Australian e-Health Research Centre . Institute of Translational Genomics and omicscience . idep NCBI account ( settings ).","title":"Other links"},{"location":"AF/","text":"Atrial Fibrillation The data is described by Nielsen JB, et al. (2018). Biobank-driven genomic discovery yields new insight into atrial fibrillation biology. Nat Genet http://csg.sph.umich.edu/willer/public/afib2018/nielsen-thorolfsdottir-willer-NG2018-AFib-gwas-summary-statistics.tbl.gz","title":"Atrial Fibrillation"},{"location":"AF/#atrial-fibrillation","text":"The data is described by Nielsen JB, et al. (2018). Biobank-driven genomic discovery yields new insight into atrial fibrillation biology. Nat Genet http://csg.sph.umich.edu/willer/public/afib2018/nielsen-thorolfsdottir-willer-NG2018-AFib-gwas-summary-statistics.tbl.gz","title":"Atrial Fibrillation"},{"location":"BMI/","text":"BMI We work on the GIANT+Biiobank data on BMI (Yengo et al. 2018), including both the genomewide wget https://portals.broadinstitute.org/collaboration/giant/images/0/0f/Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz and GCTA --cojo results as used in Mendelian Randomisation analysis downloaded below on the fly. We would refer to software-notes where information specific software can be seen from their respective directories. Visualisation The first thing is to see the Manhattan plot; in this case the P values could be extremely small and we resort to a truncated version. options(width=120) gz <- gzfile(\"Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz\") BMI <- within(read.delim(gz,as.is=TRUE), {Z <- BETA/SE}) print(subset(BMI[c(\"CHR\",\"POS\",\"SNP\",\"P\")],CHR!=16 & P<=1e-150)) library(Rmpfr) print(within(subset(BMI, P==0, select=c(CHR,POS,SNP,Z)), {P <- format(2*pnorm(mpfr(abs(Z),100),lower.tail=FALSE)); Pvalue <- pvalue(Z); log10P <- -log10p(Z)})) png(\"BMI.png\", res=300, units=\"in\", width=9, height=6) par(oma=c(0,0,0,0), mar=c(5,6.5,1,1)) mhtplot.trunc(BMI, chr=\"CHR\", bp=\"POS\", z=\"Z\", snp=\"SNP\", suggestiveline=FALSE, genomewideline=-log10(1e-8), cex.mtext=1.2, cex.text=1.2, annotatelog10P=156, annotateTop = FALSE, highlight=c(\"rs13021737\",\"rs17817449\",\"rs6567160\"), mtext.line=3, y.brk1=200, y.brk2=280, cex.axis=1.2, cex.y=1.2, cex=0.5, y.ax.space=20, col = c(\"blue4\", \"skyblue\") ) dev.off() Note especially those P values equal to zero -- pvalue() and R/Rmpfr both give the minimum approximately 1.26e-479. Nevertheless, it is safer to generate -log10(P) on the fly -- in the plot chromosome.16 stands out which would not be so should we restrict ourselves only to nonzero P values. We went further to highlight three SNPs. Independent signals ( zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ head -1 zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ awk '(NR>1 && $9<=1e-8)' | \\ sort -k1,1n -k2,2n ) > BMI.dat module load gcc/5.2.0 R --no-save -q < BMI.R > BMI.out where the module command prepares for appropriate version of R to be enabled and BMI.R selects independent signals as follows, options(echo=FALSE) BMI <- read.delim(\"BMI.dat\",as.is=TRUE)[c(\"CHR\",\"POS\",\"SNP\",\"BETA\",\"SE\",\"P\")] require(reshape) BMI <- rename(BMI,c(CHR=\"Chrom\",POS=\"End\",SNP=\"MarkerName\",BETA=\"Effect\",SE=\"StdErr\",P=\"P.value\")) require(gap) chrs <- with(BMI,unique(Chrom)) for(chr in chrs) { print(chr) ps <- subset(BMI[c(\"Chrom\",\"End\",\"MarkerName\",\"Effect\",\"StdErr\")],Chrom==chr) row.names(ps) <- 1:nrow(ps) sentinels(ps,chr,1) } It is noted that awk has problem dealing with very small values and the code is altered slightly as follows, ( zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ head -1 zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ awk ' function abs(x) { if (x<0) return -x; else return x; } (NR>1 && abs($7/$8) >= 5.730729)' | \\ sort -k1,1n -k2,2n ) > BMI.dat R --no-save -q < BMI.R > BMI.out Then BMI.out has 632 entries instead of 626, i.e., six were recovered. Note also the magic value 5.730729 is obtained from qnorm(1-0.5e-8) from R. Annotation As a follow-up to the earlier GIANT analysis, we have in the directory results from PhenoScanner for the 97 SNPs described in the SUMSTATS repository module load phenoscanner/phenoscanner_v2 phenoscanner -c All -l No -p 0.00001 -i 97.snps -o 97 For the GIANT+UKB data above, the setup is awk 'NR>1' BMI.dat | \\ cut -f3 > BMI.rsid phenoscanner -c All -l No -p 0.00001 -i BMI.rsid -o BMI in both cases, results could be expanded by allowing for LD. Pathway analysis gunzip -c Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz | awk ' { FS=OFS=\"\\t\" if(NR==1) print \"SNP\",\"Chr\",\"Pos\",\"P\" else if($9<=5e-8) print $3,$1,$2,$9 }' | gzip -f > BMI.txt.gz where we opt to customise the header/column rather than the DEPICT configuration file. Moreover, the (hg19) chromosomal positions are eventually back in the data which would facilitate GCTA --cojo analysis and mirrors https://github.com/jinghuazhao/SUMSTATS. As usual, we make a call to BMI.cfg via depict.py BMI.cfg where the DEPICT_v1_rel194.tar.gz version is used. Once started, there was complaint that Retrieving background loci Exiting.. To few background files in data/backgrounds/nloci723_nperm500_kb500_rsq0.1_mhc25000000-35000000_colld0.5-collection-1000genomespilot-depict-150429/. Please remove the folder, rerun DEPICT and contact tunepers@broadinstitute.org if the error prevails. Follow instruction and remove the directory. It is very slow-going, ~20 hours on our Linux node but surprisingly half that time under my Windows 10 whose directory zipped and then unzipped under Linux and run depict.py there. We then generate BMI.xlsx as in PW-pipelne . While there are 859 genesets with FDR<0.05, tissue enrichment shows compelingly an overwhelming role of the nervous system. This is detailed from PW-pipeline/wiki for the analysis. Partitioned heritabilty Information for the documentation example is available from software-notes . Here we carry on with the .gz file above. gunzip -c Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz > ldsc.txt python munge_sumstats.py --sumstats ldsc.txt --a1 Tested_Allele --a2 Other_allele --merge-alleles w_hm3.snplist --out ldsc --a1-inc where we fix the header with appropriate command-line parameters. We see ldsc.sumstats.gz and ldsc.log and carry on with python ldsc.py --h2 ldsc.sumstats.gz\\ --ref-ld-chr baseline_v1.1/baseline.\\ --w-ld-chr 1000G_Phase3_weights_hm3_no_MHC/weights.hm3_noMHC.\\ --overlap-annot\\ --frqfile-chr 1000G_Phase3_frq/1000G.EUR.QC.\\ --out ldsc_baseline to generate ldsc_baseline.results and ldsc_baseline.log and python ldsc.py --h2 ldsc.sumstats.gz\\ --w-ld-chr 1000G_Phase3_weights_hm3_no_MHC/weights.hm3_noMHC.\\ --ref-ld-chr 1000G_Phase3_cell_type_groups/cell_type_group.3.,baseline_v1.1/baseline.\\ --overlap-annot\\ --frqfile-chr 1000G_Phase3_frq/1000G.EUR.QC.\\ --out ldsc_CNS\\ --print-coefficients for ldsc_baseline.results and ldsc_baseline.log . Mendelian Randomisation A documented example on BMI-lung cancer is adapted in software-notes but our focus here is on BMI-T2D from DIAGRAM, wget -qO- https://portals.broadinstitute.org/collaboration/giant/images/e/e2/Meta-analysis_Locke_et_al+UKBiobank_2018_top_941_from_COJO_analysis_UPDATED.txt.gz > BMI-COJO.gz R --no-save -q < MR.R > MR.log and call MR.R to generate MR.log and MR.pdf . TWAS We start with MetaXcan as follows, cd /home/jhz22/D/genetics/hakyimlab/MetaXcan/software ./MetaXcan.py \\ --model_db_path /home/jhz22/D/genetics/hakyimlab/PredictDB/GTEx-V7_HapMap-2017-11-29/gtex_v7_Brain_Amygdala_imputed_europeans_tw_0.5_signif.db \\ --covariance /home/jhz22/D/genetics/hakyimlab/PredictDB/GTEx-V7_HapMap-2017-11-29/gtex_v7_Brain_Amygdala_imputed_eur_covariances.txt.gz \\ --gwas_file ldsc.txt \\ --snp_column SNP \\ --effect_allele_column Tested_Allele \\ --non_effect_allele_column Other_Allele \\ --beta_column BETA \\ --pvalue_column P \\ --output_file MX.csv where instead of chromosome-specific summary statistics as shown in software-notes we use ldsc.txt created above directly with results contained in MX.csv and screen output MX.log . We would also be tempting to contrast results with FUSION, gunzip -c Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz | awk ' { FS=OFS=\"\\t\" if(NR==1) print \"SNP\",\"A1\",\"A2\",\"Z\" else print $3,$4,$5,$7/$8 }' > fusion.txt for chr in $(seq 22) do Rscript FUSION.assoc_test.R --sumstats fusion.txt \\ --weight1s WEIGHTS/NTR.BLOOD.RNAARR.pos --weights_dir WEIGHTS/ \\ --ref_ld_chr LDREF/1000G.EUR. --chr $chr --out fusion.$chr.dat done Note again the header/column is customised differently from its DEPICT counterpart and results are obtained by chromosome. Two additional aspects are useful to explore: Fine-mapping In line with the fact that both TWAS and GWAS z scores are available, the option --caviar natually put them as input files for CARIAR , for chr in $(seq 22) do Rscript FUSION.assoc_test.R \\ --sumstats fusion.txt \\ --weights /home/jhz22/D/mrc/genetics/FUSION/GE/CMC.BRAIN.RNASEQ.pos \\ --weights_dir /home/jhz22/D/mrc/genetics/FUSION/GE/ \\ --ref_ld_chr /home/jhz22/D/genetics/fusion_twas/LDREF/1000G.EUR. \\ --chr $chr \\ --caviar \\ --out caviar done which are CAVIAR.EQTL.Z, CAVIAR.GWAS.Z, CAVIAR.LD triplets with prefix caviar.genename. Colocalisation This is furnished with --coloc_P --GWASN , for chr in $(seq 22) do Rscript FUSION.assoc_test.R \\ --sumstats fusion.txt \\ --weights /home/jhz22/D/mrc/genetics/FUSION/GE/CMC.BRAIN.RNASEQ.pos \\ --weights_dir /home/jhz22/D/mrc/genetics/FUSION/GE/ \\ --ref_ld_chr /home/jhz22/D/genetics/fusion_twas/LDREF/1000G.EUR. \\ --chr $chr \\ --coloc_P 5e-8 \\ --GWASN 70000 \\ --out coloc$chr.dat done Prediction See software-notes on the use of utils/make_score.R , which is based on the best model. Approximately independent LD blocks We can use these blocks genomewide or a specific gene, e.g., MC4R, awk 'NR>1' ldsc.txt | sort -k1,1n -k2,2n | awk ' { OFS=\"\\t\" if (NR==1) print \"#chrom\", \"Start\", \"End\", \"SNP\", \"A1\", \"A2\", \"FreqA1\", \"BETA\", \"SE\", \"P\", \"N\" print \"chr\" $1, $2-1, $2, $3, $4, $5, $6, $7, $8, $9, $10 }' > BMI.bed # EUR.bed is now with FM-pipeline intersectBed -a BMI.bed -b EUR.bed -loj | cut -f12-14 --complement > BMI.txt cut -f4,10 BMI.txt > BMI.snpandp # gene-based association vegas2v2 -G -snpandp BMI.snpandp -custom $PWD/g1000p3_EUR -glist glist-hg19 -out genes # pathway-based association awk '(NR>1){OFS=\"\\t\";gsub(/\"/,\"\",$0);print $2,$8}' genes.out > BMI.geneandp vegas2v2 -P -geneandp BMI.geneandp -glist glist-hg19 -geneandpath biosystems20160324.vegas2pathSYM -out pathways # grep MC4R glist-hg19 --> 18 58038563 58040001 MC4R # 1439 bp # EUR.bed -- > 1563 chr18 57630483 59020751 region1563 # 1390268 bp awk /region1563/ BMI.txt > MC4R.txt # wc -l MC4R.txt # 1342 SNPs cut -f4,10 MC4R.txt > MC4R.snpandp echo MC4R > MC4R.genelist vegas2v2 -G -snpandp MC4R.snpandp -custom $PWD/g1000p3_EUR -glist glist-hg19 -genelist MC4R.genelist -out MC4R The reason to use ldsc.txt is to allow for the possibility of finemapping. Colocalisation analysis This can be explored with https://github.com/joepickrell/gwas-pw. Assuming that bmi_height.gz has per-SNP z values and variances, the analysis proceeds with ```bash gwas-pw -i bmi_height.gz -bed EUR.bed -phenos BMI HEIGHT ```` giving results on four models (1. BMI only, 2. HEIGHT only, 3. both, 4. separate) significance. References Yengo L, et al (2018). Meta-analysis of genome-wide association studies for height and body mass index in ~700,000 individuals of European ancestry. Hum Mol Genet 27(20):3641\u20133649, BioRxiv, https://www.biorxiv.org/content/10.1101/274654v2.","title":"BMI"},{"location":"BMI/#bmi","text":"We work on the GIANT+Biiobank data on BMI (Yengo et al. 2018), including both the genomewide wget https://portals.broadinstitute.org/collaboration/giant/images/0/0f/Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz and GCTA --cojo results as used in Mendelian Randomisation analysis downloaded below on the fly. We would refer to software-notes where information specific software can be seen from their respective directories.","title":"BMI"},{"location":"BMI/#visualisation","text":"The first thing is to see the Manhattan plot; in this case the P values could be extremely small and we resort to a truncated version. options(width=120) gz <- gzfile(\"Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz\") BMI <- within(read.delim(gz,as.is=TRUE), {Z <- BETA/SE}) print(subset(BMI[c(\"CHR\",\"POS\",\"SNP\",\"P\")],CHR!=16 & P<=1e-150)) library(Rmpfr) print(within(subset(BMI, P==0, select=c(CHR,POS,SNP,Z)), {P <- format(2*pnorm(mpfr(abs(Z),100),lower.tail=FALSE)); Pvalue <- pvalue(Z); log10P <- -log10p(Z)})) png(\"BMI.png\", res=300, units=\"in\", width=9, height=6) par(oma=c(0,0,0,0), mar=c(5,6.5,1,1)) mhtplot.trunc(BMI, chr=\"CHR\", bp=\"POS\", z=\"Z\", snp=\"SNP\", suggestiveline=FALSE, genomewideline=-log10(1e-8), cex.mtext=1.2, cex.text=1.2, annotatelog10P=156, annotateTop = FALSE, highlight=c(\"rs13021737\",\"rs17817449\",\"rs6567160\"), mtext.line=3, y.brk1=200, y.brk2=280, cex.axis=1.2, cex.y=1.2, cex=0.5, y.ax.space=20, col = c(\"blue4\", \"skyblue\") ) dev.off() Note especially those P values equal to zero -- pvalue() and R/Rmpfr both give the minimum approximately 1.26e-479. Nevertheless, it is safer to generate -log10(P) on the fly -- in the plot chromosome.16 stands out which would not be so should we restrict ourselves only to nonzero P values. We went further to highlight three SNPs.","title":"Visualisation"},{"location":"BMI/#independent-signals","text":"( zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ head -1 zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ awk '(NR>1 && $9<=1e-8)' | \\ sort -k1,1n -k2,2n ) > BMI.dat module load gcc/5.2.0 R --no-save -q < BMI.R > BMI.out where the module command prepares for appropriate version of R to be enabled and BMI.R selects independent signals as follows, options(echo=FALSE) BMI <- read.delim(\"BMI.dat\",as.is=TRUE)[c(\"CHR\",\"POS\",\"SNP\",\"BETA\",\"SE\",\"P\")] require(reshape) BMI <- rename(BMI,c(CHR=\"Chrom\",POS=\"End\",SNP=\"MarkerName\",BETA=\"Effect\",SE=\"StdErr\",P=\"P.value\")) require(gap) chrs <- with(BMI,unique(Chrom)) for(chr in chrs) { print(chr) ps <- subset(BMI[c(\"Chrom\",\"End\",\"MarkerName\",\"Effect\",\"StdErr\")],Chrom==chr) row.names(ps) <- 1:nrow(ps) sentinels(ps,chr,1) } It is noted that awk has problem dealing with very small values and the code is altered slightly as follows, ( zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ head -1 zcat Meta-analysis_Locke_et_al+UKBiobank_2018_UPDATED.txt.gz | \\ awk ' function abs(x) { if (x<0) return -x; else return x; } (NR>1 && abs($7/$8) >= 5.730729)' | \\ sort -k1,1n -k2,2n ) > BMI.dat R --no-save -q < BMI.R > BMI.out Then BMI.out has 632 entries instead of 626, i.e., six were recovered. Note also the magic value 5.730729 is obtained from qnorm(1-0.5e-8) from R.","title":"Independent signals"},{"location":"BMI/#annotation","text":"As a follow-up to the earlier GIANT analysis, we have in the directory results from PhenoScanner for the 97 SNPs described in the SUMSTATS repository module load phenoscanner/phenoscanner_v2 phenoscanner -c All -l No -p 0.00001 -i 97.snps -o 97 For the GIANT+UKB data above, the setup is awk 'NR>1' BMI.dat | \\ cut -f3 > BMI.rsid phenoscanner -c All -l No -p 0.00001 -i BMI.rsid -o BMI in both cases, results could be expanded by allowing for LD.","title":"Annotation"},{"location":"BMI/#pathway-analysis","text":"gunzip -c Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz | awk ' { FS=OFS=\"\\t\" if(NR==1) print \"SNP\",\"Chr\",\"Pos\",\"P\" else if($9<=5e-8) print $3,$1,$2,$9 }' | gzip -f > BMI.txt.gz where we opt to customise the header/column rather than the DEPICT configuration file. Moreover, the (hg19) chromosomal positions are eventually back in the data which would facilitate GCTA --cojo analysis and mirrors https://github.com/jinghuazhao/SUMSTATS. As usual, we make a call to BMI.cfg via depict.py BMI.cfg where the DEPICT_v1_rel194.tar.gz version is used. Once started, there was complaint that Retrieving background loci Exiting.. To few background files in data/backgrounds/nloci723_nperm500_kb500_rsq0.1_mhc25000000-35000000_colld0.5-collection-1000genomespilot-depict-150429/. Please remove the folder, rerun DEPICT and contact tunepers@broadinstitute.org if the error prevails. Follow instruction and remove the directory. It is very slow-going, ~20 hours on our Linux node but surprisingly half that time under my Windows 10 whose directory zipped and then unzipped under Linux and run depict.py there. We then generate BMI.xlsx as in PW-pipelne . While there are 859 genesets with FDR<0.05, tissue enrichment shows compelingly an overwhelming role of the nervous system. This is detailed from PW-pipeline/wiki for the analysis.","title":"Pathway analysis"},{"location":"BMI/#partitioned-heritabilty","text":"Information for the documentation example is available from software-notes . Here we carry on with the .gz file above. gunzip -c Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz > ldsc.txt python munge_sumstats.py --sumstats ldsc.txt --a1 Tested_Allele --a2 Other_allele --merge-alleles w_hm3.snplist --out ldsc --a1-inc where we fix the header with appropriate command-line parameters. We see ldsc.sumstats.gz and ldsc.log and carry on with python ldsc.py --h2 ldsc.sumstats.gz\\ --ref-ld-chr baseline_v1.1/baseline.\\ --w-ld-chr 1000G_Phase3_weights_hm3_no_MHC/weights.hm3_noMHC.\\ --overlap-annot\\ --frqfile-chr 1000G_Phase3_frq/1000G.EUR.QC.\\ --out ldsc_baseline to generate ldsc_baseline.results and ldsc_baseline.log and python ldsc.py --h2 ldsc.sumstats.gz\\ --w-ld-chr 1000G_Phase3_weights_hm3_no_MHC/weights.hm3_noMHC.\\ --ref-ld-chr 1000G_Phase3_cell_type_groups/cell_type_group.3.,baseline_v1.1/baseline.\\ --overlap-annot\\ --frqfile-chr 1000G_Phase3_frq/1000G.EUR.QC.\\ --out ldsc_CNS\\ --print-coefficients for ldsc_baseline.results and ldsc_baseline.log .","title":"Partitioned heritabilty"},{"location":"BMI/#mendelian-randomisation","text":"A documented example on BMI-lung cancer is adapted in software-notes but our focus here is on BMI-T2D from DIAGRAM, wget -qO- https://portals.broadinstitute.org/collaboration/giant/images/e/e2/Meta-analysis_Locke_et_al+UKBiobank_2018_top_941_from_COJO_analysis_UPDATED.txt.gz > BMI-COJO.gz R --no-save -q < MR.R > MR.log and call MR.R to generate MR.log and MR.pdf .","title":"Mendelian Randomisation"},{"location":"BMI/#twas","text":"We start with MetaXcan as follows, cd /home/jhz22/D/genetics/hakyimlab/MetaXcan/software ./MetaXcan.py \\ --model_db_path /home/jhz22/D/genetics/hakyimlab/PredictDB/GTEx-V7_HapMap-2017-11-29/gtex_v7_Brain_Amygdala_imputed_europeans_tw_0.5_signif.db \\ --covariance /home/jhz22/D/genetics/hakyimlab/PredictDB/GTEx-V7_HapMap-2017-11-29/gtex_v7_Brain_Amygdala_imputed_eur_covariances.txt.gz \\ --gwas_file ldsc.txt \\ --snp_column SNP \\ --effect_allele_column Tested_Allele \\ --non_effect_allele_column Other_Allele \\ --beta_column BETA \\ --pvalue_column P \\ --output_file MX.csv where instead of chromosome-specific summary statistics as shown in software-notes we use ldsc.txt created above directly with results contained in MX.csv and screen output MX.log . We would also be tempting to contrast results with FUSION, gunzip -c Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz | awk ' { FS=OFS=\"\\t\" if(NR==1) print \"SNP\",\"A1\",\"A2\",\"Z\" else print $3,$4,$5,$7/$8 }' > fusion.txt for chr in $(seq 22) do Rscript FUSION.assoc_test.R --sumstats fusion.txt \\ --weight1s WEIGHTS/NTR.BLOOD.RNAARR.pos --weights_dir WEIGHTS/ \\ --ref_ld_chr LDREF/1000G.EUR. --chr $chr --out fusion.$chr.dat done Note again the header/column is customised differently from its DEPICT counterpart and results are obtained by chromosome. Two additional aspects are useful to explore:","title":"TWAS"},{"location":"BMI/#fine-mapping","text":"In line with the fact that both TWAS and GWAS z scores are available, the option --caviar natually put them as input files for CARIAR , for chr in $(seq 22) do Rscript FUSION.assoc_test.R \\ --sumstats fusion.txt \\ --weights /home/jhz22/D/mrc/genetics/FUSION/GE/CMC.BRAIN.RNASEQ.pos \\ --weights_dir /home/jhz22/D/mrc/genetics/FUSION/GE/ \\ --ref_ld_chr /home/jhz22/D/genetics/fusion_twas/LDREF/1000G.EUR. \\ --chr $chr \\ --caviar \\ --out caviar done which are CAVIAR.EQTL.Z, CAVIAR.GWAS.Z, CAVIAR.LD triplets with prefix caviar.genename.","title":"Fine-mapping"},{"location":"BMI/#colocalisation","text":"This is furnished with --coloc_P --GWASN , for chr in $(seq 22) do Rscript FUSION.assoc_test.R \\ --sumstats fusion.txt \\ --weights /home/jhz22/D/mrc/genetics/FUSION/GE/CMC.BRAIN.RNASEQ.pos \\ --weights_dir /home/jhz22/D/mrc/genetics/FUSION/GE/ \\ --ref_ld_chr /home/jhz22/D/genetics/fusion_twas/LDREF/1000G.EUR. \\ --chr $chr \\ --coloc_P 5e-8 \\ --GWASN 70000 \\ --out coloc$chr.dat done","title":"Colocalisation"},{"location":"BMI/#prediction","text":"See software-notes on the use of utils/make_score.R , which is based on the best model.","title":"Prediction"},{"location":"BMI/#approximately-independent-ld-blocks","text":"We can use these blocks genomewide or a specific gene, e.g., MC4R, awk 'NR>1' ldsc.txt | sort -k1,1n -k2,2n | awk ' { OFS=\"\\t\" if (NR==1) print \"#chrom\", \"Start\", \"End\", \"SNP\", \"A1\", \"A2\", \"FreqA1\", \"BETA\", \"SE\", \"P\", \"N\" print \"chr\" $1, $2-1, $2, $3, $4, $5, $6, $7, $8, $9, $10 }' > BMI.bed # EUR.bed is now with FM-pipeline intersectBed -a BMI.bed -b EUR.bed -loj | cut -f12-14 --complement > BMI.txt cut -f4,10 BMI.txt > BMI.snpandp # gene-based association vegas2v2 -G -snpandp BMI.snpandp -custom $PWD/g1000p3_EUR -glist glist-hg19 -out genes # pathway-based association awk '(NR>1){OFS=\"\\t\";gsub(/\"/,\"\",$0);print $2,$8}' genes.out > BMI.geneandp vegas2v2 -P -geneandp BMI.geneandp -glist glist-hg19 -geneandpath biosystems20160324.vegas2pathSYM -out pathways # grep MC4R glist-hg19 --> 18 58038563 58040001 MC4R # 1439 bp # EUR.bed -- > 1563 chr18 57630483 59020751 region1563 # 1390268 bp awk /region1563/ BMI.txt > MC4R.txt # wc -l MC4R.txt # 1342 SNPs cut -f4,10 MC4R.txt > MC4R.snpandp echo MC4R > MC4R.genelist vegas2v2 -G -snpandp MC4R.snpandp -custom $PWD/g1000p3_EUR -glist glist-hg19 -genelist MC4R.genelist -out MC4R The reason to use ldsc.txt is to allow for the possibility of finemapping.","title":"Approximately independent LD blocks"},{"location":"BMI/#colocalisation-analysis","text":"This can be explored with https://github.com/joepickrell/gwas-pw. Assuming that bmi_height.gz has per-SNP z values and variances, the analysis proceeds with ```bash gwas-pw -i bmi_height.gz -bed EUR.bed -phenos BMI HEIGHT ```` giving results on four models (1. BMI only, 2. HEIGHT only, 3. both, 4. separate) significance.","title":"Colocalisation analysis"},{"location":"BMI/#references","text":"Yengo L, et al (2018). Meta-analysis of genome-wide association studies for height and body mass index in ~700,000 individuals of European ancestry. Hum Mol Genet 27(20):3641\u20133649, BioRxiv, https://www.biorxiv.org/content/10.1101/274654v2.","title":"References"},{"location":"CAD/","text":"CAD/MI The summary statistics is from http://www.cardiogramplusc4d.org/, notably * CARDIoGRAM GWA meta-analysis Schunkert H, K\u00f6nig IR, Kathiresan S, Reilly MP, Assimes TL, Holm H et al. Large-scale association analysis identifies 13 new susceptibility loci for coronary artery disease. Nat Genet. 2011 43: 333-338 CARDIoGRAMplusC4D 1000 Genomes-based GWAS Nikpey M, Goel A, Won H, Hall LM, Willenborg C, Kanoni S, Saleheen S, et al. A comprehensive 1000 Genomes\u2013based genome-wide association meta-analysis of coronary artery disease. Nat Genet 2015 47:1121-1130 UKBB.GWAS1KG.EXOME.CAD.SOFT.META.PublicRelease.300517 Nelson CP, Goel A, Butterworth AS, Kanoni S, Webb TR, et al. Association analyses based on false discovery rate implicate new loci for coronary artery disease. Nat Genet 2017 Jul 17 49(9): 1385-1391. doi: 10.1038/ng.3913 For the CARDIoGRAMplusC4D 1000 Genomes-based GWAS, the setup is wget http://www.cardiogramplusc4d.org/media/cardiogramplusc4d-consortium/data-downloads/cad.additive.Oct2015.pub.zip unzip cad.additive.Oct2015.pub.zip giving `cad.add.160614.website.txt. MR We examine MMP-12 and CAD as in the Nature paper, the input data is generated with MMP12.sh . THe analogous coding for TwoSampleMR as with MendelianRandomization in software-notes is contained in MMP12.R . We could also follow Generalised Summary-data-based Mendelian Randomisation ( GSMR ). # 16-7-2019 JHZ awk ' { if (NR==1) print \"SNP\", \"A1\", \"A2\", \"freq\", \"b\", \"se\", \"p\", \"N\"; else { CHR=$2 POS=$3 a1=$4 a2=$5 if (a1>a2) snpid=\"chr\" CHR \":\" POS \"_\" a2 \"_\" a1; else snpid=\"chr\" CHR \":\" POS \"_\" a1 \"_\" a2 $1=snpid print snpid, a1, a2, $6, $9, $10, $11, 185000 } }' CAD/cad.add.160614.website.txt > gsmr_outcome.txt # awk 'NR==1' CAD/cad.add.160614.website.txt | sed 's|\\t|\\n|g' | awk '{print \"# \" NR, $1}' # 1 markername # 2 chr # 3 bp_hg19 # 4 effect_allele # 5 noneffect_allele # 6 effect_allele_freq # 7 median_info # 8 model # 9 beta # 10 se_dgc # 11 p_dgc # 12 het_pvalue # 13 n_studies xport INF=/rds/project/jmmh2/rds-jmmh2-projects/olink_proteomics/scallop/INF echo $INF/INTERVAL/INTERVAL > gsmr_ref_data echo IL.6 $INF/work/IL.6.ma > gsmr_exposure echo CAD gsmr_outcome.txt > gsmr_outcome gcta-1.9 --mbfile gsmr_ref_data --gsmr-file gsmr_exposure gsmr_outcome --gsmr-direction 0 --effect-plot --out gsmr_result R --no-save -q <<END source(\"http://cnsgenomics.com/software/gcta/static/gsmr_plot.r\") gsmr_data <- read_gsmr_data(\"gsmr_result.eff_plot.gz\") gsmr_summary(gsmr_data) plot_gsmr_effect(gsmr_data, \"IL.6\", \"cad\", colors()[75]) END where we use IL.6 as exposure data; the effect-size plots are generated. Note that gcta-1.9 indcates GCTA 1.9.x is necessary since the --mfile option is not recognised by GCTA 1.26.0. Pathway analysis MAGMA is illustrated here, The GWAS summary data can either be formatted with R, R --no-save <<END d <- read.delim(\"`cad.add.160614.website.txt\",as.is=TRUE) db <- \"CAD\" write.table(d[c(\"SNP\",\"CHR\",\"BP\")],file=paste0(db,\".snploc\"),quote=FALSE,row.name=FALSE,col.names=FALSE,sep=\"\\t\") write.table(d[c(\"SNP\",\"P\",\"NOBS\")],file=paste0(db,\".pval\"),quote=FALSE,row.name=FALSE,sep=\"\\t\") END or more efficiently with bash before pathway analysis awk -vOFS=\"\\t\" '{print $2,$1,$4}' g1000_eur.bim > g1000_eur.snploc awk -vOFS=\"\\t\" '{if(NR==1) print \"SNP\", \"P\", \"NOBS\"; else print $1,$11,1000}' `cad.add.160614.website.txt > CAD.pval # Annotation magma --annotate window=50,50 --snp-loc g1000_eur.snploc --gene-loc NCBI37.3.gene.loc --out CAD # Gene analysis - SNP p-values magma --bfile g1000_eur --pval CAD.pval ncol=NOBS --gene-annot CAD.genes.annot --out CAD # Pathway analysis # http://software.broadinstitute.org/gsea/downloads.jsp magma --gene-results CAD.genes.raw --set-annot msigdb.v6.2.entrez.gmt self-contained --model fwer --out CAD","title":"CAD/MI"},{"location":"CAD/#cadmi","text":"The summary statistics is from http://www.cardiogramplusc4d.org/, notably * CARDIoGRAM GWA meta-analysis Schunkert H, K\u00f6nig IR, Kathiresan S, Reilly MP, Assimes TL, Holm H et al. Large-scale association analysis identifies 13 new susceptibility loci for coronary artery disease. Nat Genet. 2011 43: 333-338 CARDIoGRAMplusC4D 1000 Genomes-based GWAS Nikpey M, Goel A, Won H, Hall LM, Willenborg C, Kanoni S, Saleheen S, et al. A comprehensive 1000 Genomes\u2013based genome-wide association meta-analysis of coronary artery disease. Nat Genet 2015 47:1121-1130 UKBB.GWAS1KG.EXOME.CAD.SOFT.META.PublicRelease.300517 Nelson CP, Goel A, Butterworth AS, Kanoni S, Webb TR, et al. Association analyses based on false discovery rate implicate new loci for coronary artery disease. Nat Genet 2017 Jul 17 49(9): 1385-1391. doi: 10.1038/ng.3913 For the CARDIoGRAMplusC4D 1000 Genomes-based GWAS, the setup is wget http://www.cardiogramplusc4d.org/media/cardiogramplusc4d-consortium/data-downloads/cad.additive.Oct2015.pub.zip unzip cad.additive.Oct2015.pub.zip giving `cad.add.160614.website.txt.","title":"CAD/MI"},{"location":"CAD/#mr","text":"We examine MMP-12 and CAD as in the Nature paper, the input data is generated with MMP12.sh . THe analogous coding for TwoSampleMR as with MendelianRandomization in software-notes is contained in MMP12.R . We could also follow Generalised Summary-data-based Mendelian Randomisation ( GSMR ). # 16-7-2019 JHZ awk ' { if (NR==1) print \"SNP\", \"A1\", \"A2\", \"freq\", \"b\", \"se\", \"p\", \"N\"; else { CHR=$2 POS=$3 a1=$4 a2=$5 if (a1>a2) snpid=\"chr\" CHR \":\" POS \"_\" a2 \"_\" a1; else snpid=\"chr\" CHR \":\" POS \"_\" a1 \"_\" a2 $1=snpid print snpid, a1, a2, $6, $9, $10, $11, 185000 } }' CAD/cad.add.160614.website.txt > gsmr_outcome.txt # awk 'NR==1' CAD/cad.add.160614.website.txt | sed 's|\\t|\\n|g' | awk '{print \"# \" NR, $1}' # 1 markername # 2 chr # 3 bp_hg19 # 4 effect_allele # 5 noneffect_allele # 6 effect_allele_freq # 7 median_info # 8 model # 9 beta # 10 se_dgc # 11 p_dgc # 12 het_pvalue # 13 n_studies xport INF=/rds/project/jmmh2/rds-jmmh2-projects/olink_proteomics/scallop/INF echo $INF/INTERVAL/INTERVAL > gsmr_ref_data echo IL.6 $INF/work/IL.6.ma > gsmr_exposure echo CAD gsmr_outcome.txt > gsmr_outcome gcta-1.9 --mbfile gsmr_ref_data --gsmr-file gsmr_exposure gsmr_outcome --gsmr-direction 0 --effect-plot --out gsmr_result R --no-save -q <<END source(\"http://cnsgenomics.com/software/gcta/static/gsmr_plot.r\") gsmr_data <- read_gsmr_data(\"gsmr_result.eff_plot.gz\") gsmr_summary(gsmr_data) plot_gsmr_effect(gsmr_data, \"IL.6\", \"cad\", colors()[75]) END where we use IL.6 as exposure data; the effect-size plots are generated. Note that gcta-1.9 indcates GCTA 1.9.x is necessary since the --mfile option is not recognised by GCTA 1.26.0.","title":"MR"},{"location":"CAD/#pathway-analysis","text":"MAGMA is illustrated here, The GWAS summary data can either be formatted with R, R --no-save <<END d <- read.delim(\"`cad.add.160614.website.txt\",as.is=TRUE) db <- \"CAD\" write.table(d[c(\"SNP\",\"CHR\",\"BP\")],file=paste0(db,\".snploc\"),quote=FALSE,row.name=FALSE,col.names=FALSE,sep=\"\\t\") write.table(d[c(\"SNP\",\"P\",\"NOBS\")],file=paste0(db,\".pval\"),quote=FALSE,row.name=FALSE,sep=\"\\t\") END or more efficiently with bash before pathway analysis awk -vOFS=\"\\t\" '{print $2,$1,$4}' g1000_eur.bim > g1000_eur.snploc awk -vOFS=\"\\t\" '{if(NR==1) print \"SNP\", \"P\", \"NOBS\"; else print $1,$11,1000}' `cad.add.160614.website.txt > CAD.pval # Annotation magma --annotate window=50,50 --snp-loc g1000_eur.snploc --gene-loc NCBI37.3.gene.loc --out CAD # Gene analysis - SNP p-values magma --bfile g1000_eur --pval CAD.pval ncol=NOBS --gene-annot CAD.genes.annot --out CAD # Pathway analysis # http://software.broadinstitute.org/gsea/downloads.jsp magma --gene-results CAD.genes.raw --set-annot msigdb.v6.2.entrez.gmt self-contained --model fwer --out CAD","title":"Pathway analysis"},{"location":"T2D/","text":"T2D The diagram summary statistics used in the BMI-T2D analysis is available from http://www.diagram-consortium.org/downloads.html. It is necessary to check the box in front of \"I agree with the terms above.\" to download the file, TransEthnic_T2D_GWAS.MegaMeta.2014OCT16.zip , so unzip TransEthnic_T2D_GWAS.MegaMeta.2014OCT16.zip gives diagram.mega-meta.txt . Pathway analysis As before we prepare for DEPICT file, awk '{ OFS=\"\\t\" if(NR==1) print \"SNP\",\"Chr\",\"Pos\",\"P\" else print $1,$2,$3,$9 }' diagram.mega-meta.txt | gzip -f > T2D.txt.gz and T2D.cfg slightly changed from its BMI counterpart. mtCOJO analysis For this analysis, the latest version of GCTA is required. To imitate the documentation script, we regenerate the bmi_test.raw as follows gunzip -c /home/jhz22/D/genetics/broad/ftp/Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz | \\ awk '{OFS=\"\\t\"; if(NR==1) {print \"SNP\",\"A1\",\"A2\",\"freq\",\"b\",\"se\",\"p\",\"N\"} else print $3,$4,$5,$6,$7,$8,$9,$10}' | \\ uniq > bmi_test.raw which uses uniq to remove duplicate lines. As for T2D, awk ' function f(x) {return exp(x)/(1+exp(x))} { if (NR==1) print \"SNP\",\"A1\",\"A2\",\"freq\",\"b\",\"se\",\"p\",\"N\" print $1,$4,$5,rand(),f($6),(f($8)-f($7))/2,$9,$10 } ' /home/jhz22/D/genetics/ldsc/diagram.mega-meta.txt > t2d_test.raw Since the summary statistics does not contain effect allele frequencies and we assign a random variable to run through. Now we download and unpack the LD scores from https://data.broadinstitute.org/alkesgroup/LDSCORE/, wget -qO- https://data.broadinstitute.org/alkesgroup/LDSCORE/eur_ref_ld_chr.tar.bz2 | tar fvxz - wget -qO- https://data.broadinstitute.org/alkesgroup/LDSCORE/eur_w_ld_chr.tar.bz2 | tar fvxz - At last we could trick GCTA with GSMR's test_data.zip wget http://cnsgenomics.com/software/gsmr/static/test_data.zip unzip test_data echo gsmr_example > mtcojo_ref_data.txt echo -e \"t2d t2d_test.raw 0.176306984 0.09\\nbmi bmi_test.raw\" > mtcojo_summary_data.list gcta64 --mbfile mtcojo_ref_data.txt --mtcojo-file mtcojo_summary_data.list --ref-ld-chr eur_w_ld_chr/ --w-ld-chr eur_w_ld_chr/ --out test_mtcojo_result which proceeds with no complaints though the results won't be sensible in this case. See also http://cnsgenomics.com/software/gsmr/ for the R counterpart.","title":"T2D"},{"location":"T2D/#t2d","text":"The diagram summary statistics used in the BMI-T2D analysis is available from http://www.diagram-consortium.org/downloads.html. It is necessary to check the box in front of \"I agree with the terms above.\" to download the file, TransEthnic_T2D_GWAS.MegaMeta.2014OCT16.zip , so unzip TransEthnic_T2D_GWAS.MegaMeta.2014OCT16.zip gives diagram.mega-meta.txt .","title":"T2D"},{"location":"T2D/#pathway-analysis","text":"As before we prepare for DEPICT file, awk '{ OFS=\"\\t\" if(NR==1) print \"SNP\",\"Chr\",\"Pos\",\"P\" else print $1,$2,$3,$9 }' diagram.mega-meta.txt | gzip -f > T2D.txt.gz and T2D.cfg slightly changed from its BMI counterpart.","title":"Pathway analysis"},{"location":"T2D/#mtcojo-analysis","text":"For this analysis, the latest version of GCTA is required. To imitate the documentation script, we regenerate the bmi_test.raw as follows gunzip -c /home/jhz22/D/genetics/broad/ftp/Meta-analysis_Locke_et_al+UKBiobank_2018.txt.gz | \\ awk '{OFS=\"\\t\"; if(NR==1) {print \"SNP\",\"A1\",\"A2\",\"freq\",\"b\",\"se\",\"p\",\"N\"} else print $3,$4,$5,$6,$7,$8,$9,$10}' | \\ uniq > bmi_test.raw which uses uniq to remove duplicate lines. As for T2D, awk ' function f(x) {return exp(x)/(1+exp(x))} { if (NR==1) print \"SNP\",\"A1\",\"A2\",\"freq\",\"b\",\"se\",\"p\",\"N\" print $1,$4,$5,rand(),f($6),(f($8)-f($7))/2,$9,$10 } ' /home/jhz22/D/genetics/ldsc/diagram.mega-meta.txt > t2d_test.raw Since the summary statistics does not contain effect allele frequencies and we assign a random variable to run through. Now we download and unpack the LD scores from https://data.broadinstitute.org/alkesgroup/LDSCORE/, wget -qO- https://data.broadinstitute.org/alkesgroup/LDSCORE/eur_ref_ld_chr.tar.bz2 | tar fvxz - wget -qO- https://data.broadinstitute.org/alkesgroup/LDSCORE/eur_w_ld_chr.tar.bz2 | tar fvxz - At last we could trick GCTA with GSMR's test_data.zip wget http://cnsgenomics.com/software/gsmr/static/test_data.zip unzip test_data echo gsmr_example > mtcojo_ref_data.txt echo -e \"t2d t2d_test.raw 0.176306984 0.09\\nbmi bmi_test.raw\" > mtcojo_summary_data.list gcta64 --mbfile mtcojo_ref_data.txt --mtcojo-file mtcojo_summary_data.list --ref-ld-chr eur_w_ld_chr/ --w-ld-chr eur_w_ld_chr/ --out test_mtcojo_result which proceeds with no complaints though the results won't be sensible in this case. See also http://cnsgenomics.com/software/gsmr/ for the R counterpart.","title":"mtCOJO analysis"}]}